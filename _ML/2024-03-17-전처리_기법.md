---
layout: post
title: 전처리 기법
date: 2024-03-17 04:20:00 +0900
---
### LabelEncoder
- 정의
  <p class="sub">범주형 데이터(ex: 문자열)를 숫자형 데이터로 변환하는 전처리 기법 중 하나입니다. Scikit-lean 라이브러리에서 제공하는 LabelEncoder 클래스를 통해 구현할 수 있습니다. 이 방법은 문자열로 된 라벨을 숫자로 변환하여 머신러닝 알고리즘이 이해할 수 있는 형태로 만들어 줍니다.</p>
- 사용하는 이유
  <table>
  <tr>
  <td>머신러닝 모델 호환성</td>
  <td>대부분의 머신러닝 모델은 숫자형 입력을 기대합니다. 범주형 데이터를 그래도 사용할 경우, 모델이 이를 올바르게 이해하고 처리할 수 없습니다. 따라서, 범주형 데이터를 숫자형으로 변환하는 과정이 필요합니다.</td>
  </tr>
  <tr>
  <td>데이터 전처리 단순화</td>
  <td>라벨 인코딩은 범주형 데이터를 간단하게 숫자형 데이터로 변환할 수 있는 방법을 제공합니다. 이는 데이터 전처리 과정을 단순화시키고 모델 학습 과정을 용이하게 합니다.</td>
  </tr>
  <tr>
  <td>학습 효율성 향상</td>
  <td>숫자형으로 변환된 데이터는 계산이 용이하며, 모델 학습 시간을 단축시킬 수 있습니다. 또한, 데이터의 차원을 불필요하게 증가시키지 않으면서도 범주형 정보를 모델에 전달할 수 있습니다.</td>
  </tr>
  </table>
- 주의할 점
  <p class="sub">라벨 인코딩은 숫자의 크고 작음에 대한 정보를 모델에 부여할 수 있기 때문에 순서가 없는 범주형 데이터에 대해서는 잘못된 정보를 전달할 수 있습니다. 이런 경우 One-Hot Encoding과 같은 다른 전처리 기법을 고려할 수 있습니다.</p>

### Min-Max scaling
- 정의
  <p class="sub">데이터 스케일링 방법 중 하나로, 모든 특성의 값을 0과 1 사이의 범위로 조정하는 방법입니다. 데이터의 최소값은 0이되고 최대값은 1이 됩니다.</p>
- 공식
  <table>
  <tr>
  <td class="letex">$$X_{scaled}= \frac {X - X_{min}} {X_{max}-X_{min}}$$</td>
  <td class="letex-desc">
  $X$ : 원래 값 <br/>
  $X_{min}$ : 해당 특성에서의 최소값 <br/>
  $X_{max}$ : 해당 특성에서의 최대값 <br/>
  $X_{scaled}$ : 스케일링 후의 값
  </td>
  </tr>
  </table>
- 사용하는 이유
  <table>
  <tr>
  <td>특성 간의 일관된 스케일</td>
  <td>머신러닝 모델, 특히 거리 기반 알고리즘에서는 모든 특성이 동일한 스케일을 갖는 것이 중요합니다. Min-max scaling을 통해 모든 특성 범위를 동일하게 조정할 수 있습니다.</td>
  </tr>
  <tr>
  <td>경사 하강법의 수렴 속도 향상</td>
  <td>경사 하강법(Gradient Descent)과 같은 최적화 알고리즘은 스케일이 조정된 데이터에서 더 빠르게 수렴할 수 있습니다.</td>
  </tr>
  </table>

- 주의할 점
  <table>
  <tr>
  <td>이상치 영향</td>
  <td>min-max scaling 은 이상치에 매우 민감합니다. 이상치가 있을 경우, 대부분의 데이터가 매우 좁은 범위 내에 압출될 수 있습니다.</td>
  </tr>
  <tr>
  <td>데이터의 분포 변화</td>
  <td>min-max scaline은 데이터의 분포를 변경하지 않지만, 모든 데이터를 0과 1 사이로 압축합니다. 때로는 데이터의 원래 값을 유지하는 것이 모델 성능에 더 유리할 수 있습니다.</td>
  </tr>
  </table>

### Standard Scaler
- 정의
  <p class="sub">데이터의 특성 평균을 0으로 표준편차(분산)를 1로 조정하여 모든 특성들이 같은 스케일을 갖도록 만드는 방법입니다. 이를 통해 모델이 더 빠르고 정확하게 학습할 수 있도록 돕습니다.</p>
- 공식
  <table>
  <tr>
  <td class="letex">$$z = \frac {(x - \mu)} {\sigma}$$</td>
  <td class="letex-desc">
  $x$ : 기존 데이터 포인트 <br/>
  $\mu$ : 특성의 평균 <br/>
  $\sigma$ : 표준편차
  </td>
  </tr>
  </table>
- 사용하는 이유
  <table>
  <tr>
  <td>성능 향상</td>
  <td>많은 머신러닝 알고리즘은 특성들의 스케일이 비슷할 때 더 잘 작동합니다. 예를 들어, 경사 하강법(Gradient Descent)과 같은 최적화 알고리즘은 모든 특성의 스케일이 비슷할 때 더 빠르게 수렴합니다.</td>
  </tr>
  <tr>
  <td>학습 효율성</td>
  <td>특성들의 스케일 차이가 클 경우, 모델 학습 과정에서 일부 특성이 다른 특성보다 더 큰 영향을 미칠 수 있습니다. 이는 모델이 중요한 특성을 제대로 학습하지 못하게 만들 수 있습니다.</td>
  </tr>
  <tr>
  <td>알고리즘 요구사항 충족</td>
  <td>일부 알고리즘, 특히 거리 기반 알고리즘(SVM 등)과 선형모델은 특성의 스케일이 모델의 성능에 큰 영향을 미칩니다. 이러한 알고리즘들은 특성들이 동일한 스케일을 갖도록 전처리하는 것이 중요합니다.</td>
  </tr>
  <tr>
  <td>이상치 영향 최소화</td>
  <td>표준화 과정은 이상치가 평균과 분산에 미치는 영향을 줄여줍니다. 비록 완벽하게 이상치를 제거하지는 못하지만, 이상치의 영향을 줄여 전체 데이터 셋의 특성을 더 잘 반영하게 합니다.</td>
  </tr>
  <tr>
  <td>모델 해석 용이</td>
  <td>데이터가 표준화되면, 모델의 가중치를 직접 비교할 수 있게 됩니다. 이는 각 특성이 결과에 미치는 상대적 중요도를 이해하는 데 도움이 됩니다.</td>
  </tr>
  </table>
- 주의할 점
  <table>
  <tr>
  <td>이상치가 많을 경우</td>
  <td>Standard Scaler는 평균과 표준편차를 기반으로 데이터를 스케일링합니다. 따라서, 이상치가 있을 경우 평균과 표준편차가 크게 왜곡될 수 있으며, 이는 전체 스케일링 과정에 영향을 미칩니다. 이상치가 많은 데이터에는 Robust Scaler와 같은 다른 스케일링 방법을 고려하는 것이 좋습니다.</td>
  </tr>
  <tr>
  <td>데이터 분포 영향</td>
  <td>Standard Scaler는 데이터가 정규 분포를 따른다는 가정 하에 최적의 성능을 발휘합니다. 데이터가 크게 비대칭이거나 정규 분포를 따르지 않는 경우, 변환된 데이터가 모델 학습에 최적이 아닐 수 있씁니다. 이 경우, Power Transformer나 Quantile Transformer와 같은 다른 전처리 기법을 고려할 수 있습니다.</td>
  </tr>
  <tr>
  <td>특성의 스케일 필요성 판단</td>
  <td>일부 특성은 원래의 스케일을 유지하는 게 모델 성능에 더 유리할 수 있습니다. 예를 들어, 일부 카테고리형 변수는 원-핫 인코딩을 통해 처리될 때 스케일링 없이 사용되는 것이 좋습니다.</td>
  </tr>
  <tr>
  <td>모델 종류에 따른 필요성 판단</td>
  <td>모든 머신러닝 모델이 스케일링을 필요로 하는 것은 아닙니다. 예를 들어, 결정 트리(Decision Trees)와 랜덤 포레스트(Random Forsets)와 같은 트리 기반 모델은 특성의 스케일에 영향을 받지 않습니다. 따라서, 사용하는 모델의 특성을 고려하여 스케일링의 필요성을 판단해야 합니다.</td>
  </tr>
  </table>

### Robust Scaler
- 정의
  <p class="sub">통계 데이터의 중앙값(median)과 사분위수 범위를 사용하여 특성의 스케일을 조정하는 방법입니다. 이 방법은 특히 이상치에 강건(robust)하기 때문에 Robust Scaler라고 불립니다.
  Robust Scaler는 박스 플롯에 사용되는 중앙값과 사분위수 범위(IQR) 개념을 기반으로 하기 때문에 박스 플롯과 매우 밀접한 관련이 있습니다. 따라서 Robust Scaler로 스케일링한 후 데이터의 분포와 이상치의 영향을 확인하기 위해서는 박스 플롯을 사용하는 것이 매우 효과적입니다.</p>
- 공식
  <table>
  <tr>
  <td class="letex">$$M_{scaled} = \frac {X - Median(X)} {IQR(X)}$$</td>
  <td class="letex-desc">
  $X$ : 원래 특성
  $Median(X)$ : X의 중앙값
  $IQR(X)$ : $X$의 사분위수 범위
  </td>
  </tr>
  </table>
- 사용하는 이유
  <table>
  <tr>
  <td>이상치에 강건함</td>
  <td>Robust Scaler는 중앙값(median)과 사분위수 범위(IQR)를 사용하여 데이터를 스케일링합니다. 이 방법은 평균과 표준편차를 사용하는 방법에 비해 이상치의 영향을 훨씬 덜 받습니다. 따라서, 데이터에 이상치가 많은 경우에도 안정적인 스케일링이 가능합니다.</td>
  </tr>
  <tr>
  <td>특성 간 일관된 스케일</td>
  <td>다양한 범위를 가진 특성들을 모델링할 때, 모든 특성을 동일한 스케일로 조정함으로써 모델이 각 특성을 공정하게 처리할 수 있도록 합니다. 이는 특히 거리 기반 알고리즘에서 중요합니다.</td>
  </tr>
  <tr>
  <td>데이터 구조 유지</td>
  <td>Robust Scaler는 데이터의 중앙값을 기준으로 스케일링 하기 때문에 데이터의 전반적 분포 구조를 유지하면서 스케일링할 수 있씁니다. 이는 데이터의 해석 가능성을 유지하는 데 도움이 됩니다.</td>
  </tr>
  </table>
- 주의할 점
  <table>
  <tr>
  <td>데이터 분포 변화</td>
  <td>Robust Scaler는 중앙값과 IQR을 사용하여 데이터를 스케일링하기 때문에 원본 데이터의 분포 형태가 변할 수 있씁니다. 특히, 정규 분포를 가정하는 모델을 사용할 경우 스케일링 후 데이터가 이러한 가정과 맞지 않을 수 있습니다.</td>
  </tr>
  <tr>
  <td>이상치 처리</td>
  <td>Robust Scaler는 이상치의 영향을 줄이지만, 이상치를 완전히 제거하거나 수정하지는 않습니다. 때로는 이상치를 별도로 처리하는 것이 모델의 성능에 더 도움이 될 수 있습니다.</td>
  </tr>
  <tr>
  <td>상황에 따른 적합성</td>
  <td>모든 스케일링 방법이 그렇듯 Robust Scaler도 모든 상황에 최적의 선택은 아닙니다. 예를 들어 데이터에 이상치가 거의 없고 모든 특성이 비슷한 범위를 가질 때는 Standard Scaler나 Min-Max Scaler가 더 적합할 수 있습니다.</td>
  </tr>
  <tr>
  <td>모델 종속성</td>
  <td>사용하는 머신러닝 모델에 따라 스케일링의 필요성과 방법이 달라질 수 있습니다. 예를 들어 결정 트리나 랜덤 포레스트와 같은 모델은 특성의 스케일에 덜 민감하기 때문에, Robust Scaler를 사용할 필요가 없을 수 있습니다.</td>
  </tr>
  </table>