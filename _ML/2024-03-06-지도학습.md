---
layout: post
title: 지도학습(Supervised Learning) 
date: 2024-03-06 01:37:23 +0900
---
### Decision Tree(결정 트리)
- 정의
  <p class="sub">분류와 회귀 문제에 널리 사용되는 머신러닝 알고리즘으로 데이터를 분석하여 데이터의 패턴을 학습하고, 학습된 패턴을 기반으로 결정 규칙을 Tree 구조로 구성하여 예측을 수행합니다.
  </p>
- 분할 기준(Split Criterion) : 트리의 각 노드에서 데이터를 분할할 때 사용하는 기준
  <table>
  <tr>
  <td>지니 계수 (Gini Impurity)</td>
  <td>한 노드가 포함하고 있는 샘플들을 무작위로 뽑았을 때 잘못 분류될 확률</td>
  </tr>
  <tr>
  <td>엔트로피 (Entropy)</td>
  <td>노드의 불순도를 측정하는 또 다른 방법으로 엔트로피가 높을 수록 데이터의 불확실성이 높다는 뜻이다.</td>
  </tr>
  <tr>
  <td>정보 이득 (Information Gain)</td>
  <td>부모와 자식 노드 간의 엔트로피 차이로 얼마나 많은 정보를 얻었는지 측정합니다.</td>
  </tr>
  </table>
- 장단점
  <p class="sub">장점 : 이해하기 쉽고 분류와 회귀 모두에 사용할 수 있다.
  단점 : 과적합 문제가 발생하기 쉽고 안정성이 낮다.
  </p>

### 앙상블(Ensemble)
- 정의
  <p class="sub">여러 학습 알고리즘을 조합하여 사용하는 방법으로, 기법 자체는 지도학습에 국한되진 않지만 주로 지도학습 문제를 해결하기 위해 사용되됩니다. 해당 기법은 단일 모델을 사용할 때보다 더 좋은 예측 성능을 얻는 것을 목적으로 합니다.</p>
- 학습 유형
  <table>
  <tr>
  <td>배깅 (Bagging)</td>
  <td>
  <li>동일한 유형의 알고리즘을 여러 개 사용</li>
  <li>훈련 데이터를 무작위로 다르게 샘플링 하여 각 모델을 다르게 학습</li>
  <li>예시 : 랜덤 포레스트(Random Forest) 등</li>
  </td>
  </tr>
  <tr>
  <td>부스팅 (Boosting)</td>
  <td>
  <li>여러 약한 학습기(Weak Learner)를 순차적으로 학습시키면서 잘못 예측된 데이터에 많은 가중치를 부여하여 오류를 개선해나가는 방식</li>
  <li>예시 : AdaBoost, Gradlent Boosting 등</li>
  </td>
  </tr>
  </table>
  <enter></enter>
  <enter></enter>
  - 배깅
    <table>
    <tr>
    <td>랜덤 포레스트 (Random Forest)</td>
    <td>Decision Tree (결정 트리) 기반 앙상블 학습방법으로, 여러 개의 결정 트리를 임의로 생성하여 각 트리의 예측을 결합함으로써 최종 예측을 도출합니다. 이는 단일 결정 트리가 가질 수 있는 과적합(Overfitting) 문제를 줄여주며 일반화 성능이 뛰어납니다. 랜덤 포레스트는 분류와 회귀 모두 사용할 수 있습니다.</td>
    </tr>
    </table>

  - 부스팅
    <table>
    <tr>
    <td>그라디언트 부스트 (Gradient Boosting)</td>
    <td>Decision Tree (결정 트리) 기반의 앙상블 학습방법으로, 랜덤 포레스트와 달리 순차적으로 트리를 구축하면서 이전 트리의 오류를 보완해 나가는 방식으로 작동합니다. 각 단계에서 모델은 이전 모델들의 합성으로부터 발생하는 잔차(실체 값과 예측 값의 차이)를 최소화하는 방향으로 학습합니다. 그라디언트 부스트는 높은 예측 성능을 제공하지만 파라미터 설정에 따라 과적합에 민감할 수 있습니다.</td>
    </tr>
    </table>

### SVM (Support Vector Machine)
- 정의
  <p class="sub">분류와 화귀 문제에 모두 사용할 수 있는 강력한 머신러닝 알고리즘으로, 이 알고리즘의 목표는 데이터를 분류하기 위한 최적의 경계선(고차원에서는 초평명)을 찾는 것입니다. SVM은 마진이라는 개념을 사용하여 서로 다른 클래스의 데이터 사이에 최대한의 간격을 둘 수 잇는 경계선을 찾습니다. 이는 복잡한 비선형 분류 문제를 해결 할 수 있도록 커널 기법을 사용하여 고차원 공간으로 매핑합니다.</p>
- 주의사항
  <p class="sub">기본적으로 SVM은 데이터를 선형으로 분리하는 초평면을 찾아내지만 실제로 많은 문제들은 선형으로 구분되기 어렵습니다. 이런 경우 커널 기법을 사용하여 비선형 데이터를 더 높은 차원의 공간으로 매핑하여 선형 분리가 가능하게 만듭니다. 커널 기법의 핵심 아이디어는 실제로 데이터를 고차원 공간으로 변환하지 않고도 고차원 공간에서의 내적을 계산할 수 있는 함수 즉, 커널 함수를 사용하는 것입니다. 이로 인해 계산 비용이 크게 줄어들고 고차원에서의 선형 분리가 가능해집니다.</p>
  <enter></enter>
  <enter></enter>
  - 용어 정리
    <table>
    <tr>
    <td>커널 기법</td>
    <td>서포트 벡터 머신 (SVM) 같은 알고리즘에서 자주 사용되는 기법으로 커널 기법의 핵심 아이디어는 고차원 공간에서의 데이터 포인트 간 내적을 직접 계산하지 않고도 그 결과를 얻을 수 있는 함수 (커널 함수)를 사용하는 것입니다.</td>
    </tr>
    <tr>
    <td>내적</td>
    <td>두 벡터 (크기 + 방향) 간의 상호작용을 수치적으로 측정하는 방법으로 일반적으로 두 벡터의 각 요소의 곱의 합으로 정의되며 기하학적으로는 하나의 벡터가 다른 벡터에 투영된 크기와 방향성을 나타냅니다.</td>
    </tr>
    </table>