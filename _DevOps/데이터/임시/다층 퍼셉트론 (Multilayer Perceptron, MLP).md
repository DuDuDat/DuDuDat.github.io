---
---

> MLP는 주로 역전파 알고리즘 (backpropagation)을 통해 학습합니다. 이 알고리즘은 출력과 실제 값 사이의 오차를 최소화하기 위해 가중치를 조정합니다.

# MLP 구조

## 입력층 (Input Layer)
- 외부 데이터가 처음으로 입력되는 층
- 각 뉴런은 입력 데이터의 특징(feature)을 받아들이며, 입력 데이터의 수와 동일한 뉴런 개수를 가짐
- 예를 들어, 이미지 인식의 경우 입력층의 뉴런은 이미지의 픽셀 값을 입력으로 받음

## 은닉층 (Hidden Layer)
- 입력층과 출력층 사이에 위치하는 층
- 입력 데이터를 처리하고 변환하는 역할을 함
- 여러 층으로 구성될 수 있으며, 이 층들이 복잡한 패턴을 학습함
- 각 은닉층의 뉴런은 특정 가중치(weight)와 활성화 함수(activation function)를 사용하여 입력 데이터를 변환함
- 딥러닝에서 '딥(Deep)'은 이 은닉층이 여러 층으로 깊게 쌓여 있는 구조를 의미함

## 출력층 (Output Layer)
- 신경망의 마지막 층으로, 최종 결과를 출력함
- 출력 뉴런의 개수는 해결하려는 문제의 종류에 다라 다름 예를 들어, 이진 분류 문제에서는 하나의 뉴런이 있고, 다중 클래스 분류 문제에서는 각 클래스에 대응하는 뉴런이 있음
- 출력 뉴런들은 은닉층으로부터 전달받은 정보를 바탕으로 최종 예측을 수행함